{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import git\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "os.chdir(repo.working_dir) \n",
    "\n",
    "import yaml\n",
    "parsed_yaml_file = yaml.load(open(\"params.yaml\"), Loader=yaml.FullLoader)\n",
    "paths = parsed_yaml_file['paths']\n",
    "\n",
    "basic_dict = {\n",
    "#    'input_dim': data.features_dict_uncensored_scaled['train'].shape[1],\n",
    "    'output_dim': 2,\n",
    "    'num_groups': 4,\n",
    "    'sparse': False,\n",
    "    'group_objective_type': 'standard',\n",
    "    \n",
    "    # architecture\n",
    "    'num_hidden': 0, # does this make it equivalent to log reg?\n",
    "    \n",
    "    # general learning\n",
    "    'batch_size': 128, #take directly from data batch shape\n",
    "    'lr': 1e-4,\n",
    "    'num_epochs': 100,\n",
    "    'weighted_loss': True,\n",
    "    \"weighted_evaluation\": True,\n",
    "    \n",
    "    # logging \n",
    "    'print_every': 10,\n",
    "    'logging_evaluate_by_group': True,\n",
    "    'logging_thresholds': [0.075, 0.2],\n",
    "    'logging_metrics': ['auc', 'loss_bce'],\n",
    "    'logging_threshold_metrics': ['specificity', 'recall', 'positive_rate'],\n",
    "    \n",
    "    # global variables\n",
    "    'val_fold_id': '1',\n",
    "    'test_fold_id': 'test',\n",
    "    'feature_columns': ['age', 'totchol', 'hdlc', 'sysbp', 'rxsbp', 'unrxsbp', 'bmi',\n",
    "                   'diabt126', 'cursmoke', 'race_black', 'gender_male'],\n",
    "    'metrics': ['auc', 'auprc', 'brier', 'loss_bce']\n",
    "}\n",
    "\n",
    "BASE_CONFIG_PATH = os.path.join(BASE_PATH, 'experiments', 'basic_config.yaml')\n",
    "os.makedirs(os.path.dirname(BASE_CONFIG_PATH), exist_ok=True)\n",
    "\n",
    "with open(BASE_CONFIG_PATH, 'w') as file:\n",
    "    documents = yaml.dump(basic_dict, file)\n",
    "    \n",
    "# configs_path = '/labs/shahlab/projects/agataf/data/experiments/erm/pooled_cohorts/configs'\n",
    "# method_path = '/labs/shahlab/projects/agataf/data/experiments/erm/pooled_cohorts/'\n",
    "\n",
    "\n",
    "\n",
    "# with open(os.path.join(method_path, 'basic_config.yaml'), 'w') as file:\n",
    "#     documents = yaml.dump(basic_dict, file)\n",
    "    \n",
    "baseline_dict_update = {\n",
    "#    'input_dim': data.features_dict_uncensored_scaled['train'].shape[1],\n",
    "    'batch_size': 256,\n",
    "    'split_gender': False,\n",
    "    'num_epochs': 300,\n",
    "    'early_stopping': True,\n",
    "    'early_stopping_patience': 25,\n",
    "    'print_every': 20,\n",
    "    'print_debug': True,\n",
    "    'logging_path': ['auc', 'loss_bce']\n",
    "}\n",
    "\n",
    "# baseline_dict = basic_dict.copy()\n",
    "# baseline_dict.update(baseline_dict_update)\n",
    "\n",
    "# with open(os.path.join(configs_path, '00.yaml'), 'w') as file:\n",
    "#     documents = yaml.dump(baseline_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'erm'\n",
    "config_id = '00'\n",
    "fold_id = '0'\n",
    "BASE_PATH = '/labs/shahlab/projects/agataf/data/cohorts/pooled_cohorts'\n",
    "\n",
    "\n",
    "\n",
    "CONFIG_PATH = os.path.join(BASE_PATH, 'experiments', EXPERIMENT_NAME, 'config',\n",
    "                           '.'.join((config_id, 'yaml')))\n",
    "\n",
    "RESULT_PATH = os.path.join(BASE_PATH, 'experiments', EXPERIMENT_NAME, 'performance',\n",
    "                           '.'.join((config_id, 'yaml')), fold_id)\n",
    "\n",
    "os.makedirs(os.path.dirname(CONFIG_PATH), exist_ok=True)\n",
    "\n",
    "with open(CONFIG_PATH, 'w') as file:\n",
    "    documents = yaml.dump(baseline_dict_update, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'erm_male'\n",
    "config_id = '00'\n",
    "BASE_PATH = '/labs/shahlab/projects/agataf/data/cohorts/pooled_cohorts'\n",
    "\n",
    "CONFIG_PATH = os.path.join(BASE_PATH, 'experiments', EXPERIMENT_NAME, 'config',\n",
    "                           '.'.join((config_id, 'yaml')))\n",
    "\n",
    "dict_update = {\n",
    "#    'input_dim': data.features_dict_uncensored_scaled['train'].shape[1],\n",
    "    'batch_size': 256,\n",
    "    'split_gender': False,\n",
    "    'num_epochs': 300,\n",
    "    'early_stopping': True,\n",
    "    'early_stopping_patience': 25,\n",
    "    'print_every': 20,\n",
    "    'print_debug': True,\n",
    "    'logging_path': ['auc', 'loss_bce'],\n",
    "    'data_query': 'gender_male==1'\n",
    "}\n",
    "\n",
    "os.makedirs(os.path.dirname(CONFIG_PATH), exist_ok=True)\n",
    "\n",
    "with open(CONFIG_PATH, 'w') as file:\n",
    "    documents = yaml.dump(dict_update, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'erm_female'\n",
    "config_id = '00'\n",
    "BASE_PATH = '/labs/shahlab/projects/agataf/data/cohorts/pooled_cohorts'\n",
    "\n",
    "CONFIG_PATH = os.path.join(BASE_PATH, 'experiments', EXPERIMENT_NAME, 'config',\n",
    "                           '.'.join((config_id, 'yaml')))\n",
    "\n",
    "dict_update = {\n",
    "#    'input_dim': data.features_dict_uncensored_scaled['train'].shape[1],\n",
    "    'batch_size': 256,\n",
    "    'split_gender': False,\n",
    "    'num_epochs': 300,\n",
    "    'early_stopping': True,\n",
    "    'early_stopping_patience': 25,\n",
    "    'print_every': 20,\n",
    "    'print_debug': True,\n",
    "    'logging_path': ['auc', 'loss_bce'],\n",
    "    'data_query': 'gender_male==0'\n",
    "}\n",
    "\n",
    "os.makedirs(os.path.dirname(CONFIG_PATH), exist_ok=True)\n",
    "\n",
    "with open(CONFIG_PATH, 'w') as file:\n",
    "    documents = yaml.dump(dict_update, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lagr_dict = {\n",
    "\n",
    "    # general learning\n",
    "    'num_epochs': 300,\n",
    "    \"early_stopping\": True,\n",
    "    \"early_stopping_patience\": 10,\n",
    "    \n",
    "    # constraint\n",
    "    \"lr_lambda\": 1e-1,  # try other values\n",
    "    \"multiplier_bound\": 1, # try other values\n",
    "    \"constraint_slack\": 0.01,\n",
    "    'thresholds': [0.075, 0.2],\n",
    "    'constraint_metrics': ['fpr', 'tpr'],\n",
    "    \"use_exact_constraints\": True,\n",
    "    \"update_lambda_on_val\": False,\n",
    "    \"additive_update\": True, #explore false too\n",
    "    \"project_small_lambda\": True,\n",
    "    \n",
    "    # logging \n",
    "    'print_every': 20,\n",
    "}\n",
    "\n",
    "dro_dict = {\n",
    "    'num_epochs': 100,\n",
    "    \n",
    "    # constraint\n",
    "    \"lr_lambda\": 1,\n",
    "    \"multiplier_bound\": 10,\n",
    "    \"use_exact_constraints\": True,\n",
    "    \"update_lambda_on_val\": False,\n",
    "    \n",
    "    #logging \n",
    "    'print_every': 20,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
