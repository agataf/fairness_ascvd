{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "artificial-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import sys\n",
    "import copy\n",
    "import configargparse as argparse\n",
    "from prediction_utils.pytorch_utils.metrics import StandardEvaluator, FairOVAEvaluator\n",
    "from prediction_utils.util import yaml_write\n",
    "from lifelines import KaplanMeierFitter, LogNormalFitter, WeibullFitter\n",
    "\n",
    "\n",
    "import train_utils\n",
    "import yaml\n",
    "\n",
    "def censoring_weights(df, model_type = 'KM'):\n",
    "\n",
    "    if model_type == 'KM':\n",
    "        censoring_model = KaplanMeierFitter()\n",
    "    else:\n",
    "        raise ValueError(\"censoring_model not defined\")\n",
    "    \n",
    "    censoring_model.fit(df.query('is_train==1').event_time, 1.0*~df.query('is_train==1').event_indicator)\n",
    "    \n",
    "    weights = 1 / censoring_model.survival_function_at_times(df.event_time_10yr.values - 1e-5)\n",
    "    weights_dict = dict(zip(df.index.values, weights.values))\n",
    "    return weights_dict\n",
    "\n",
    "def get_censoring(df, by_group=True, model_type='KM'):\n",
    "    \n",
    "    if by_group:\n",
    "        weight_dict = {}\n",
    "        for group in [1, 2, 3, 4]:\n",
    "            group_df = df.query('grp==@group')\n",
    "            group_weights_dict = censoring_weights(group_df, model_type)\n",
    "            weight_dict.update(group_weights_dict)\n",
    "\n",
    "    else:\n",
    "        weight_dict = censoring_weights(cohort, censoring_model_type)\n",
    "\n",
    "    weights = pd.Series(weight_dict, name='weights') \n",
    "    return weights\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--experiment_name', type=str)\n",
    "# parser.add_argument(\"--cohort_path\", type=str, help=\"path where input cohorts are stored\", required=False,\n",
    "#                    default='/labs/shahlab/projects/agataf/data/cohorts/pooled_cohorts/cohort/all_cohorts.csv')\n",
    "# parser.add_argument('--result_path', type=str)\n",
    "# parser.add_argument('--base_config_path', type=str)\n",
    "\n",
    "# parser.set_defaults(\n",
    "#     save_outputs=False,\n",
    "#     run_evaluation=True,\n",
    "#     run_evaluation_group_standard=True,\n",
    "#     run_evaluation_group_fair_ova=True,\n",
    "#     print_debug=True,\n",
    "#     save_model_weights=False,\n",
    "#     data_query = '',\n",
    "#     num_epochs = 0\n",
    "# )\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# args = copy.deepcopy(args.__dict__)\n",
    "\n",
    "# os.makedirs(args['result_path'], exist_ok=True)\n",
    "# os.makedirs(os.path.join(args['result_path'], 'all'), exist_ok=True)\n",
    "cohort_path='/labs/shahlab/projects/agataf/data/cohorts/pooled_cohorts/cohort/all_cohorts.csv'\n",
    "cohort = pd.read_csv(cohort_path)\n",
    "cohort = cohort.assign(sysbp = lambda x: x.rxsbp+x.unrxsbp,\n",
    "                       rxbp = lambda x: (x.rxsbp>0).astype(int))\n",
    "#config_dict = yaml.load(open(args['base_config_path']), Loader=yaml.FullLoader)\n",
    "\n",
    "coefs = {'women': [0.106501, 0.432440, 0.000056, 0.017666, 0.731678, 0.943970, 1.009790, 0.151318, -0.008580, -0.003647, 0.006208, 0.152968, -0.000153, 0.115232, -0.092231, 0.070498, -0.000173, -0.000094, -12.823110],\n",
    "         'men': [0.064200, 0.482835, -0.000061, 0.038950, 2.055533, 0.842209, 0.895589, 0.193307, 0, -0.014207, 0.011609, -0.119460, 0.000025, -0.077214, -0.226771, -0.117749, 0.004190, -0.000199, -11.679980]}\n",
    "                  \n",
    "groups_dict = {1: 'women', 2: 'women', 3: 'men', 4: 'men'}\n",
    "\n",
    "data_df = (pd.DataFrame({'sex': cohort.grp.map(groups_dict),\n",
    "                         'age': cohort.age,\n",
    "                         'black': cohort.race_black,\n",
    "                         'sysbp^2': cohort.sysbp**2,\n",
    "                         'sysbp': cohort.sysbp,\n",
    "                         'rxbp': cohort.rxbp,\n",
    "                         'diabt': cohort.diabt126,\n",
    "                         'cursmoke': cohort.cursmoke,\n",
    "                         'totchol/hdlc': cohort.totchol/cohort.hdlc,\n",
    "                         'age_if_black': cohort.age*cohort.race_black,#only women\n",
    "                         'sysbp_if_rxbp': cohort.sysbp*cohort.rxbp,\n",
    "                         'sysbp_if_black': cohort.sysbp*cohort.race_black,\n",
    "                         'black_and_rxbp': cohort.rxbp*cohort.race_black, \n",
    "                         'age*sysbp': cohort.age*cohort.sysbp, \n",
    "                         'black_and_diabt': cohort.diabt126*cohort.race_black, \n",
    "                         'black_and_cursmoke': cohort.cursmoke*cohort.race_black,\n",
    "                         'totchol/hdlc_if_black': cohort.totchol/cohort.hdlc*cohort.race_black,\n",
    "                         'sysbp_if_black_and_rxbp': cohort.sysbp*cohort.rxbp*cohort.race_black,\n",
    "                         'age*sysbp_if_black': cohort.sysbp*cohort.age*cohort.race_black}\n",
    "                       )\n",
    "           .assign(intercept=1)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "necessary-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(x):\n",
    "    return 1/(1+np.exp(-1*x))\n",
    "\n",
    "risks = []\n",
    "for sex in ['women','men']:\n",
    "    risk = (data_df\n",
    "            .query(\"sex==@sex\")\n",
    "            .drop(columns='sex')\n",
    "            .multiply(coefs[sex])\n",
    "            .sum(axis=1)\n",
    "            .apply(lambda x:log_reg(x))\n",
    "                    )\n",
    "    #risk = 1 - pow(baseline_survival[group], relative_risk)\n",
    "    risks.append(risk)\n",
    "    \n",
    "risks = pd.concat(risks)\n",
    "risks.name='pred_probs'\n",
    "\n",
    "cohort = cohort.assign(is_train = lambda x: np.where((x.fold_id != 'eval') & (x.fold_id != \"test\") \n",
    "                                                         & (x.fold_id != \"eval\"),\n",
    "                                                         1, 0),\n",
    "                       labels = lambda x: x.ascvd_10yr.astype(int),\n",
    "                       model_type = 'revised_pce')\n",
    "\n",
    "all_weights = get_censoring(cohort, by_group = True, model_type = 'KM')#.sort_index()\n",
    "\n",
    "#df = df.join(all_weights)\n",
    "output_df_eval = (cohort\n",
    "           .rename(columns={'fold_id': 'phase',\n",
    "                            'grp': 'group'})\n",
    "                  .join(all_weights)\n",
    "                  .join(risks)\n",
    "           .filter(['phase', 'pred_probs', 'labels', 'weights', 'group', 'model_type', 'person_id'])\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "criminal-somerset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase</th>\n",
       "      <th>pred_probs</th>\n",
       "      <th>labels</th>\n",
       "      <th>weights</th>\n",
       "      <th>group</th>\n",
       "      <th>model_type</th>\n",
       "      <th>person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005688</td>\n",
       "      <td>0</td>\n",
       "      <td>1.069459</td>\n",
       "      <td>2</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>0</td>\n",
       "      <td>1.069459</td>\n",
       "      <td>2</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0</td>\n",
       "      <td>1.069459</td>\n",
       "      <td>2</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>0.010865</td>\n",
       "      <td>0</td>\n",
       "      <td>1.069459</td>\n",
       "      <td>2</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.093140</td>\n",
       "      <td>0</td>\n",
       "      <td>1.069459</td>\n",
       "      <td>2</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25614</th>\n",
       "      <td>3</td>\n",
       "      <td>0.136886</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000650</td>\n",
       "      <td>3</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>25614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25615</th>\n",
       "      <td>2</td>\n",
       "      <td>0.054010</td>\n",
       "      <td>0</td>\n",
       "      <td>1.090399</td>\n",
       "      <td>3</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>25615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25616</th>\n",
       "      <td>2</td>\n",
       "      <td>0.061705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.096160</td>\n",
       "      <td>3</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>25616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25617</th>\n",
       "      <td>eval</td>\n",
       "      <td>0.188953</td>\n",
       "      <td>0</td>\n",
       "      <td>1.030498</td>\n",
       "      <td>3</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>25617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25618</th>\n",
       "      <td>6</td>\n",
       "      <td>0.337278</td>\n",
       "      <td>0</td>\n",
       "      <td>1.098234</td>\n",
       "      <td>3</td>\n",
       "      <td>original_pce</td>\n",
       "      <td>25618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25619 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase  pred_probs  labels   weights  group    model_type  person_id\n",
       "0         9    0.005688       0  1.069459      2  original_pce          0\n",
       "1         1    0.009356       0  1.069459      2  original_pce          1\n",
       "2         2    0.008706       0  1.069459      2  original_pce          2\n",
       "3      test    0.010865       0  1.069459      2  original_pce          3\n",
       "4         5    0.093140       0  1.069459      2  original_pce          4\n",
       "...     ...         ...     ...       ...    ...           ...        ...\n",
       "25614     3    0.136886       0  1.000650      3  original_pce      25614\n",
       "25615     2    0.054010       0  1.090399      3  original_pce      25615\n",
       "25616     2    0.061705       0  1.096160      3  original_pce      25616\n",
       "25617  eval    0.188953       0  1.030498      3  original_pce      25617\n",
       "25618     6    0.337278       0  1.098234      3  original_pce      25618\n",
       "\n",
       "[25619 rows x 7 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "asian-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_eval = (train_utils.add_ranges(output_df_eval)\n",
    "                          .merge(cohort.filter(['person_id', 'ldlc']), how='inner', on='person_id')\n",
    "                          .assign(relative_risk = lambda x: train_utils.treat_relative_risk(x))\n",
    "                          .rename(columns={'row_id': 'person_id'})\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "inner-desert",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/labs/shahlab/projects/agataf/prediction_utils/prediction_utils/pytorch_utils/metrics.py:560: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if group_overall_name in df[group_var_name].unique():\n"
     ]
    }
   ],
   "source": [
    "output_df_eval = (train_utils.add_ranges(output_df_eval)\n",
    "                          .merge(cohort.filter(['person_id', 'ldlc']), how='inner', on='person_id')\n",
    "                          .assign(relative_risk = lambda x: train_utils.treat_relative_risk(x))\n",
    "                          .rename(columns={'row_id': 'person_id'})\n",
    "                      )\n",
    "\n",
    "# output_df_eval.to_parquet(\n",
    "#     os.path.join(args['result_path'], \"output_df.parquet\"),\n",
    "#     index=False,\n",
    "#     engine=\"pyarrow\"\n",
    "# )\n",
    "\n",
    "# output_df_eval.to_csv(\n",
    "#     os.path.join(args['result_path'], 'all', 'predictions.csv'),\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "evaluator = StandardEvaluator(#threshold_metrics = config_dict['logging_threshold_metrics'],\n",
    "                              thresholds = [0.075,0.2],\n",
    "                              metrics = ['auc', 'auprc', 'loss_bce', \n",
    "                                         'ace_rmse_logistic_log',\n",
    "                                         'ace_abs_logistic_log']\n",
    "                             )\n",
    "\n",
    "eval_general_args = {'df': output_df_eval,\n",
    "                     'label_var': 'labels',\n",
    "                     'pred_prob_var': 'pred_probs',\n",
    "                     'weight_var': 'weights', \n",
    "                     'strata_vars': ['phase'],\n",
    "                     'group_var_name': 'group'}\n",
    "\n",
    "result_df_overall = evaluator.get_result_df(**eval_general_args)\n",
    "\n",
    "# result_df_overall.to_parquet(\n",
    "#     os.path.join(args['result_path'], \"result_df_group_standard_eval.parquet\"),\n",
    "#     engine=\"pyarrow\",\n",
    "#     index=False\n",
    "# )\n",
    "\n",
    "evaluator = FairOVAEvaluator(#threshold_metrics = config_dict['logging_threshold_metrics'],\n",
    "                             thresholds = [0.075,0.2])\n",
    "    \n",
    "eval_fair_args = {'df': output_df_eval,\n",
    "                  'label_var': 'labels',\n",
    "                  'pred_prob_var': 'pred_probs',\n",
    "                  'weight_var': 'weights',\n",
    "                  'group_var_name': 'group',\n",
    "                  'strata_vars': ['phase']}\n",
    "        \n",
    "result_df_group_fair_ova = evaluator.get_result_df(**eval_fair_args)\n",
    "\n",
    "#result_df_overall.to_csv(os.path.join(args['result_path'], 'all', 'standard_evaluation.csv'), index=False)\n",
    "#result_df_group_fair_ova.to_csv(os.path.join(args['result_path'], 'all', 'fairness_evaluation.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:utility]",
   "language": "python",
   "name": "conda-env-utility-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
